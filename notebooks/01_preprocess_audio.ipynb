{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f0aaa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import logging\n",
    "import random\n",
    "import shutil\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Third-party imports\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a922076",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_config() -> Namespace:\n",
    "    \"\"\"\n",
    "    Create configuration namespace with all constants grouped.\n",
    "    \n",
    "    Returns:\n",
    "        Namespace containing all configuration parameters\n",
    "    \"\"\"\n",
    "    return Namespace(\n",
    "        # Directory paths\n",
    "        source_dir=Path(\"../audio_data/gun_sound_v2\"),\n",
    "        target_dir=Path(\"../audio_data/gun_sound_final\"),\n",
    "        dataset_dir=Path(\"../dataset\"),\n",
    "        metadata_dir=Path(\"../metadata\"),\n",
    "        \n",
    "        # Filtering criteria\n",
    "        distance_filter=\"0m\",\n",
    "        direction_filter=\"center\",\n",
    "        min_filename_parts=4,\n",
    "        \n",
    "        # File patterns\n",
    "        audio_extension=\"*.mp3\",\n",
    "        metadata_filename=\"gun_sound_final_metadata.parquet\",\n",
    "        \n",
    "        # Operation settings\n",
    "        use_move=False,  # Set to True to move instead of copy\n",
    "        skip_existing=True,\n",
    "        \n",
    "        # Progress and logging\n",
    "        log_level=logging.INFO,\n",
    "        show_examples=5,\n",
    "        \n",
    "        # Compression settings\n",
    "        compression=\"gzip\",\n",
    "        parquet_engine=\"pyarrow\",\n",
    "        \n",
    "        FEATURE_DIR=Path(\"../features\"),\n",
    "        DATASET_DIR=Path(\"../dataset\"),\n",
    "        SAMPLE_RATE=22050,\n",
    "        N_MELS=64,\n",
    "        HOP_LENGTH=512,\n",
    "    )\n",
    "\n",
    "# Create configuration\n",
    "ARGS = create_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72311d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 1013 files matching 0m/center\n",
      "🔫 Example files:\n",
      "- s12k_0m_center_1986.mp3\n",
      "- s12k_0m_center_1992.mp3\n",
      "- s12k_0m_center_1979.mp3\n",
      "- pp_0m_center_1894.mp3\n",
      "- tomy_0m_center_0812.mp3\n"
     ]
    }
   ],
   "source": [
    "# Define base directory\n",
    "AUDIO_DIR = Path(\"../audio_data/gun_sound_v2\")\n",
    "\n",
    "# Filtered list\n",
    "filtered_files = []\n",
    "\n",
    "# Loop through all .mp3 files\n",
    "for file in AUDIO_DIR.glob(\"*.mp3\"):\n",
    "    parts = file.stem.split(\"_\")  # Remove \".mp3\" and split by \"_\"\n",
    "    \n",
    "    if len(parts) >= 4:\n",
    "        gun_type, distance, direction, clip_id = parts\n",
    "        if distance == \"0m\" and direction == \"center\":\n",
    "            filtered_files.append(file)\n",
    "\n",
    "# Result\n",
    "print(f\"✅ Found {len(filtered_files)} files matching 0m/center\")\n",
    "print(\"🔫 Example files:\")\n",
    "for f in filtered_files[:5]:\n",
    "    print(\"-\", f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd2e0760",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_components = [f.name.split(\"_\") for f in filtered_files]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"file_name\": [f.name for f in filtered_files],\n",
    "    \"label\": [components[0] for components in file_components],\n",
    "    \"id\": [components[3].split(\".\")[0] for components in file_components]\n",
    "})\n",
    "# df.to_csv(\"filtered_bgg_0m_center.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfc0afa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s12k_0m_center_1986.mp3</td>\n",
       "      <td>s12k</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s12k_0m_center_1992.mp3</td>\n",
       "      <td>s12k</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s12k_0m_center_1979.mp3</td>\n",
       "      <td>s12k</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pp_0m_center_1894.mp3</td>\n",
       "      <td>pp</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tomy_0m_center_0812.mp3</td>\n",
       "      <td>tomy</td>\n",
       "      <td>0812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>ak_0m_center_0008.mp3</td>\n",
       "      <td>ak</td>\n",
       "      <td>0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>kar_0m_center_0552.mp3</td>\n",
       "      <td>kar</td>\n",
       "      <td>0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>m249_0m_center_0588.mp3</td>\n",
       "      <td>m249</td>\n",
       "      <td>0588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>m24_0m_center_1822.mp3</td>\n",
       "      <td>m24</td>\n",
       "      <td>1822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>pp_0m_center_1899.mp3</td>\n",
       "      <td>pp</td>\n",
       "      <td>1899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file_name label    id\n",
       "0     s12k_0m_center_1986.mp3  s12k  1986\n",
       "1     s12k_0m_center_1992.mp3  s12k  1992\n",
       "2     s12k_0m_center_1979.mp3  s12k  1979\n",
       "3       pp_0m_center_1894.mp3    pp  1894\n",
       "4     tomy_0m_center_0812.mp3  tomy  0812\n",
       "...                       ...   ...   ...\n",
       "1008    ak_0m_center_0008.mp3    ak  0008\n",
       "1009   kar_0m_center_0552.mp3   kar  0552\n",
       "1010  m249_0m_center_0588.mp3  m249  0588\n",
       "1011   m24_0m_center_1822.mp3   m24  1822\n",
       "1012    pp_0m_center_1899.mp3    pp  1899\n",
       "\n",
       "[1013 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05af63b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(Path(\"../metadata/gun_sound_final_metadata.paquet\"), index=False, engine=\"pyarrow\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b841b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def filter_audio_files(\n",
    "    source_dir: Path, \n",
    "    distance_filter: str = \"0m\", \n",
    "    direction_filter: str = \"center\",\n",
    "    min_parts: int = 4,\n",
    "    audio_pattern: str = \"*.mp3\"\n",
    ") -> List[Path]:\n",
    "    \"\"\"\n",
    "    Filter audio files based on distance and direction criteria.\n",
    "    \n",
    "    Args:\n",
    "        source_dir: Source directory containing audio files\n",
    "        distance_filter: Distance criteria to filter by\n",
    "        direction_filter: Direction criteria to filter by\n",
    "        min_parts: Minimum number of filename parts required\n",
    "        audio_pattern: File pattern to match\n",
    "        \n",
    "    Returns:\n",
    "        List of filtered file paths\n",
    "    \"\"\"\n",
    "    filtered_files = []\n",
    "    \n",
    "    if not source_dir.exists():\n",
    "        logger.error(f\"Source directory does not exist: {source_dir}\")\n",
    "        return filtered_files\n",
    "    \n",
    "    # Get all audio files first to show progress\n",
    "    all_files = list(source_dir.glob(audio_pattern))\n",
    "    \n",
    "    for file in tqdm(all_files, desc=\"Filtering audio files\", unit=\"file\"):\n",
    "        try:\n",
    "            parts = file.stem.split(\"_\")\n",
    "            if len(parts) >= min_parts:\n",
    "                gun_type, distance, direction, clip_id = parts[:4]\n",
    "                if distance == distance_filter and direction == direction_filter:\n",
    "                    filtered_files.append(file)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error processing file {file.name}: {e}\")\n",
    "    \n",
    "    logger.info(f\"Found {len(filtered_files)} files matching {distance_filter}/{direction_filter}\")\n",
    "    return filtered_files\n",
    "\n",
    "def copy_files_with_progress(\n",
    "    files: List[Path], \n",
    "    target_dir: Path, \n",
    "    use_move: bool = False,\n",
    "    skip_existing: bool = True\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Copy or move files to target directory with error handling.\n",
    "    \n",
    "    Args:\n",
    "        files: List of source files to copy/move\n",
    "        target_dir: Destination directory\n",
    "        use_move: If True, move files instead of copying\n",
    "        skip_existing: If True, skip files that already exist\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (successful_files, failed_files)\n",
    "    \"\"\"\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    successful_files = []\n",
    "    failed_files = []\n",
    "    \n",
    "    operation = \"Moving\" if use_move else \"Copying\"\n",
    "    logger.info(f\"{operation} {len(files)} files to {target_dir}\")\n",
    "    \n",
    "    for file in tqdm(files, desc=f\"{operation} files\", unit=\"file\"):\n",
    "        try:\n",
    "            dest_path = target_dir / file.name\n",
    "            \n",
    "            if dest_path.exists() and skip_existing:\n",
    "                logger.warning(f\"File already exists, skipping: {file.name}\")\n",
    "                continue\n",
    "                \n",
    "            if use_move:\n",
    "                shutil.move(str(file), str(dest_path))\n",
    "            else:\n",
    "                shutil.copy2(file, dest_path)\n",
    "                \n",
    "            successful_files.append(file.name)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to {operation.lower()} {file.name}: {e}\")\n",
    "            failed_files.append(file.name)\n",
    "    \n",
    "    return successful_files, failed_files\n",
    "\n",
    "def create_metadata_dataframe(\n",
    "    files: List[Path],\n",
    "    metadata_dir: Path,\n",
    "    filename: str,\n",
    "    compression: str = \"gzip\",\n",
    "    engine: str = \"pyarrow\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create metadata dataframe and save to parquet file.\n",
    "    \n",
    "    Args:\n",
    "        files: List of audio files\n",
    "        metadata_dir: Directory to save metadata\n",
    "        filename: Metadata filename\n",
    "        compression: Compression method\n",
    "        engine: Parquet engine\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with file metadata\n",
    "    \"\"\"\n",
    "    metadata_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    file_components = [f.name.split(\"_\") for f in files]\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"file_name\": [f.name for f in files],\n",
    "        \"label\": [components[0] for components in file_components],\n",
    "        \"id\": [components[3].split(\".\")[0] for components in file_components]\n",
    "    })\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata_path = metadata_dir / filename\n",
    "    df.to_parquet(metadata_path, index=False, engine=engine, compression=compression)\n",
    "    logger.info(f\"Saved metadata to {metadata_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_audio_files(args: Namespace) -> None:\n",
    "    \"\"\"\n",
    "    Main processing function using configuration from Namespace.\n",
    "    \n",
    "    Args:\n",
    "        args: Configuration namespace\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Filter files\n",
    "        filtered_files = filter_audio_files(\n",
    "            args.source_dir, \n",
    "            args.distance_filter, \n",
    "            args.direction_filter,\n",
    "            args.min_filename_parts,\n",
    "            args.audio_extension\n",
    "        )\n",
    "        \n",
    "        if not filtered_files:\n",
    "            logger.warning(\"No files found matching the criteria\")\n",
    "            return\n",
    "        \n",
    "        # Step 2: Copy/move files\n",
    "        successful_files, failed_files = copy_files_with_progress(\n",
    "            filtered_files, \n",
    "            args.target_dir, \n",
    "            args.use_move,\n",
    "            args.skip_existing\n",
    "        )\n",
    "        \n",
    "        # Step 3: Create metadata\n",
    "        if successful_files:\n",
    "            # Filter to only successfully processed files\n",
    "            processed_files = [f for f in filtered_files if f.name in successful_files]\n",
    "            create_metadata_dataframe(\n",
    "                processed_files,\n",
    "                args.metadata_dir,\n",
    "                args.metadata_filename,\n",
    "                args.compression,\n",
    "                args.parquet_engine\n",
    "            )\n",
    "        \n",
    "        # Step 4: Summary\n",
    "        logger.info(f\"✅ Successfully processed {len(successful_files)} files\")\n",
    "        if failed_files:\n",
    "            logger.error(f\"❌ Failed to process {len(failed_files)} files\")\n",
    "        \n",
    "        # Show examples\n",
    "        print(f\"\\n✅ Processed {len(successful_files)} files to {args.target_dir}\")\n",
    "        if failed_files:\n",
    "            print(f\"❌ Failed to process {len(failed_files)} files\")\n",
    "        \n",
    "        print(f\"\\n🔫 Example files (showing first {args.show_examples}):\")\n",
    "        for f in successful_files[:args.show_examples]:\n",
    "            print(f\"   - {f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Critical error during processing: {e}\")\n",
    "        raise\n",
    "\n",
    "# Execute the processing\n",
    "process_audio_files(ARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539bcdc0",
   "metadata": {},
   "source": [
    "### Step - Shuffle and split dataset to (train/test/val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccc5e023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Copying 1536 files to: ../dataset/train\n",
      "📁 Copying 329 files to: ../dataset/val\n",
      "📁 Copying 330 files to: ../dataset/test\n",
      "✅ Dataset split complete.\n"
     ]
    }
   ],
   "source": [
    "# Split ratio\n",
    "SPLIT_RATIOS = {\n",
    "    \"train\": 0.7,\n",
    "    \"val\": 0.15,\n",
    "    \"test\": 0.15\n",
    "}\n",
    "\n",
    "# Shuffle seed\n",
    "random.seed(42)\n",
    "\n",
    "# Step 1: Gather all files\n",
    "all_files = list(ARGS.source_dir.glob(\"*.mp3\"))\n",
    "random.shuffle(all_files)\n",
    "\n",
    "# Step 2: Split files\n",
    "total = len(all_files)\n",
    "n_train = int(total * SPLIT_RATIOS[\"train\"])\n",
    "n_val = int(total * SPLIT_RATIOS[\"val\"])\n",
    "n_test = total - n_train - n_val\n",
    "\n",
    "splits = {\n",
    "    \"train\": all_files[:n_train],\n",
    "    \"val\": all_files[n_train:n_train + n_val],\n",
    "    \"test\": all_files[n_train + n_val:]\n",
    "}\n",
    "\n",
    "# Step 3: Copy files to target folders\n",
    "for split_name, split_files in splits.items():\n",
    "    split_dir = ARGS.dataset_dir / split_name\n",
    "    split_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"📁 Copying {len(split_files)} files to: {split_dir}\")\n",
    "    for file in split_files:\n",
    "        shutil.copy(file, split_dir / file.name)\n",
    "\n",
    "print(\"✅ Dataset split complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d87fdf",
   "metadata": {},
   "source": [
    "### Step - Convert audio to Log-Mel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b96b602e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔖 Gun type labels: {'ak': 0, 'aug': 1, 'awm': 2, 'dbs': 3, 'deagle': 4, 'dp': 5, 'g36c': 6, 'gro': 7, 'k2': 8, 'kar': 9, 'm16': 10, 'm24': 11, 'm249': 12, 'm4': 13, 'mini': 14, 'mk': 15, 'nogun': 16, 'p18c': 17, 'p1911': 18, 'p90': 19, 'p92': 20, 'pp': 21, 'pump': 22, 'qbu': 23, 'qbz': 24, 'r1895': 25, 'r45': 26, 's12k': 27, 'scar': 28, 'sks': 29, 'slr': 30, 'tomy': 31, 'ump': 32, 'uzi': 33, 'vec': 34, 'verl': 35, 'vss': 36, 'win': 37}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a00c45b660a43df88e3bd74ba38293e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔁 Processing train:   0%|          | 0/1536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31970cfa774e457ba3d499ded44d1897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔁 Processing val:   0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e7d965bbea46d0be96247e0ab5c4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔁 Processing test:   0%|          | 0/330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature extraction complete and saved to: /Users/ittichaiboonyarakthunya/Documents/WorkDir/ai-ml/labs-gunshot-classification/features\n"
     ]
    }
   ],
   "source": [
    "# 🔖 Auto-generate label map\n",
    "LABELS = sorted({f.stem.split(\"_\")[0] for f in (ARGS.DATASET_DIR / \"train\").glob(\"*.mp3\")})\n",
    "LABEL_MAP = {label: idx for idx, label in enumerate(LABELS)}\n",
    "print(\"🔖 Gun type labels:\", LABEL_MAP)\n",
    "\n",
    "def extract_logmel(audio_path):\n",
    "    y, _ = librosa.load(audio_path, sr=ARGS.SAMPLE_RATE)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=ARGS.SAMPLE_RATE, n_mels=ARGS.N_MELS, hop_length=ARGS.HOP_LENGTH)\n",
    "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "    return log_mel\n",
    "\n",
    "def process_split(split):\n",
    "    input_dir = ARGS.DATASET_DIR / split\n",
    "    output_dir = ARGS.FEATURE_DIR / split\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for audio_file in tqdm(list(input_dir.glob(\"*.mp3\")), desc=f\"🔁 Processing {split}\"):\n",
    "        gun_type = audio_file.stem.split(\"_\")[0]\n",
    "        label = LABEL_MAP[gun_type]\n",
    "\n",
    "        try:\n",
    "            logmel = extract_logmel(audio_file)\n",
    "            out_name = f\"{audio_file.stem}.npy\"\n",
    "            np.save(output_dir / out_name, {\n",
    "                \"features\": logmel.astype(np.float32),\n",
    "                \"label\": label\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed to process {audio_file.name}: {e}\")\n",
    "\n",
    "# Run all splits\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    process_split(split)\n",
    "\n",
    "# Save label map\n",
    "import json\n",
    "with open(ARGS.FEATURE_DIR / \"labels.json\", \"w\") as f:\n",
    "    json.dump(LABEL_MAP, f)\n",
    "\n",
    "print(\"✅ Feature extraction complete and saved to:\", ARGS.FEATURE_DIR.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
